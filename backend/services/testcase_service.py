"""
AIæµ‹è¯•ç”¨ä¾‹ç”ŸæˆæœåŠ¡
ä½¿ç”¨AutoGen 0.5.7å®ç°å¤šæ™ºèƒ½ä½“åä½œ
ä»¿ç…§ examples/agent/testcase_agents.py å®ç°å¤šæ™ºèƒ½ä½“åä½œ
å‚è€ƒ examples/topic.py ä½¿ç”¨ SingleThreadedAgentRuntime + RoutedAgent + ClosureAgent
"""

import asyncio
import base64
import uuid
from dataclasses import dataclass
from datetime import datetime
from typing import Any, AsyncGenerator, Awaitable, Callable, List, Optional

from autogen_agentchat.agents import AssistantAgent, UserProxyAgent
from autogen_agentchat.base import TaskResult
from autogen_agentchat.conditions import MaxMessageTermination, TextMentionTermination
from autogen_agentchat.messages import (
    ModelClientStreamingChunkEvent,
    TextMessage,
    UserInputRequestedEvent,
)
from autogen_agentchat.teams import RoundRobinGroupChat
from autogen_core import (
    CancellationToken,
    ClosureAgent,
    ClosureContext,
    DefaultTopicId,
    MessageContext,
    RoutedAgent,
    SingleThreadedAgentRuntime,
    TopicId,
    TypeSubscription,
    message_handler,
    type_subscription,
)
from loguru import logger
from pydantic import BaseModel, Field

# æ·»åŠ æ–‡ä»¶è§£æç›¸å…³å¯¼å…¥
try:
    from llama_index.core import Document, SimpleDirectoryReader
except ImportError:
    logger.warning("æ— æ³•å¯¼å…¥llama_indexï¼Œæ–‡ä»¶è§£æåŠŸèƒ½å°†ä¸å¯ç”¨")
    Document = None
    SimpleDirectoryReader = None

from backend.models.chat import (
    AgentMessage,
    AgentType,
    FileUpload,
    TestCaseRequest,
    TestCaseResponse,
    TestCaseStreamChunk,
)

try:
    from examples.llms import openai_model_client
except ImportError:
    logger.warning("æ— æ³•å¯¼å…¥openai_model_clientï¼Œè¯·æ£€æŸ¥examples/llms.py")
    openai_model_client = None

# æ·»åŠ æ–‡ä»¶è§£æå·¥å…·å‡½æ•°
try:
    from rag_system.rag.utils import extract_text_from_llm
except ImportError:
    logger.warning("æ— æ³•å¯¼å…¥extract_text_from_llmï¼Œå°†ä½¿ç”¨ç®€å•æ–‡ä»¶è¯»å–")

    def extract_text_from_llm(file_path: str) -> str:
        """ç®€å•çš„æ–‡ä»¶è¯»å–å®ç°"""
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                return f.read()
        except Exception as e:
            logger.error(f"æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
            return ""


# å®šä¹‰topicç±»å‹ - ä»¿ç…§examples/agent/testcase_agents.py
requirement_analysis_topic_type = "requirement_analysis"
testcase_generation_topic_type = "testcase_generation"
user_feedback_topic_type = "user_feedback"
testcase_review_topic_type = "testcase_review"
task_result_topic_type = "collect_result"

# ä¸ºäº†å…¼å®¹æ€§ï¼Œä¿ç•™æ—§çš„topicå¸¸é‡
REQUIREMENT_ANALYSIS_TOPIC = requirement_analysis_topic_type
TESTCASE_GENERATION_TOPIC = testcase_generation_topic_type
USER_FEEDBACK_TOPIC = user_feedback_topic_type
RESULT_COLLECTION_TOPIC = task_result_topic_type


# å®šä¹‰æ¶ˆæ¯ç±»å‹ - ä»¿ç…§examples/agent/testcase_agents.py
class RequirementMessage(BaseModel):
    """éœ€æ±‚æ¶ˆæ¯ - ä»¿ç…§examples"""

    text_content: Optional[str] = Field(default="", description="æ–‡æœ¬å†…å®¹")
    files: Optional[List[FileUpload]] = Field(default=None, description="ä¸Šä¼ çš„æ–‡ä»¶")
    conversation_id: str = Field(..., description="å¯¹è¯ID")
    round_number: int = Field(default=1, description="è½®æ¬¡")
    user_feedback: Optional[str] = Field(default=None, description="ç”¨æˆ·åé¦ˆ")


class ResponseMessage(BaseModel):
    """å“åº”æ¶ˆæ¯ - ä»¿ç…§examples"""

    source: str = Field(..., description="æ¶ˆæ¯æ¥æº")
    content: str = Field(..., description="æ¶ˆæ¯å†…å®¹")
    is_final: bool = Field(default=False, description="æ˜¯å¦æœ€ç»ˆæ¶ˆæ¯")


@dataclass
class TestCaseMessage:
    """æµ‹è¯•ç”¨ä¾‹æ¶ˆæ¯ - ä»¿ç…§examples"""

    source: str
    content: Any


# ä¸ºäº†å…¼å®¹æ€§ï¼Œä¿ç•™ä¸€äº›æ—§çš„æ¶ˆæ¯ç±»å‹
class RequirementAnalysisMessage(BaseModel):
    """éœ€æ±‚åˆ†ææ¶ˆæ¯ - å…¼å®¹æ€§"""

    content: str = Field(..., description="ç”¨æˆ·ä¸Šä¼ çš„å†…å®¹")
    files: Optional[List[dict]] = Field(default=None, description="ä¸Šä¼ çš„æ–‡ä»¶ä¿¡æ¯")
    conversation_id: str = Field(..., description="å¯¹è¯ID")
    round_number: int = Field(default=1, description="è½®æ¬¡")


class TestCaseGenerationMessage(BaseModel):
    """æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆæ¶ˆæ¯ - å…¼å®¹æ€§"""

    requirements: str = Field(..., description="åˆ†æåçš„éœ€æ±‚")
    conversation_id: str = Field(..., description="å¯¹è¯ID")
    round_number: int = Field(..., description="è½®æ¬¡")


class UserFeedbackMessage(BaseModel):
    """ç”¨æˆ·åé¦ˆæ¶ˆæ¯ - å…¼å®¹æ€§"""

    feedback: str = Field(..., description="ç”¨æˆ·åé¦ˆå†…å®¹")
    previous_testcases: str = Field(..., description="ä¹‹å‰ç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹")
    conversation_id: str = Field(..., description="å¯¹è¯ID")
    round_number: int = Field(..., description="è½®æ¬¡")


class AgentResultMessage(BaseModel):
    """æ™ºèƒ½ä½“ç»“æœæ¶ˆæ¯ - å…¼å®¹æ€§"""

    content: str = Field(..., description="æ™ºèƒ½ä½“è¾“å‡ºå†…å®¹")
    agent_type: str = Field(..., description="æ™ºèƒ½ä½“ç±»å‹")
    agent_name: str = Field(..., description="æ™ºèƒ½ä½“åç§°")
    conversation_id: str = Field(..., description="å¯¹è¯ID")
    round_number: int = Field(..., description="è½®æ¬¡")
    timestamp: str = Field(..., description="æ—¶é—´æˆ³")
    is_complete: bool = Field(default=False, description="æ˜¯å¦å®Œæˆ")


class TestCaseService:
    """AIæµ‹è¯•ç”¨ä¾‹ç”ŸæˆæœåŠ¡"""

    def __init__(self):
        self.active_conversations = {}  # å­˜å‚¨æ´»è·ƒçš„å¯¹è¯çŠ¶æ€
        self.max_rounds = 3  # æœ€å¤§äº¤äº’è½®æ¬¡
        self.collected_messages = {}  # æ”¶é›†çš„æ¶ˆæ¯ï¼ŒæŒ‰å¯¹è¯IDåˆ†ç»„
        logger.info("AIæµ‹è¯•ç”¨ä¾‹ç”ŸæˆæœåŠ¡åˆå§‹åŒ–å®Œæˆ")

    async def get_document_from_files(self, files: list[str]) -> str:
        """è·å–æ–‡ä»¶å†…å®¹"""
        logger.info(f"å¼€å§‹è§£ææ–‡ä»¶ | æ–‡ä»¶æ•°é‡: {len(files)}")
        try:
            if not SimpleDirectoryReader or not Document:
                raise Exception("llama_indexæœªå®‰è£…ï¼Œæ— æ³•è§£ææ–‡ä»¶")

            data = SimpleDirectoryReader(input_files=files).load_data()
            doc = Document(text="\n\n".join([d.text for d in data[0:]]))
            logger.success(f"æ–‡ä»¶è§£æå®Œæˆ | å†…å®¹é•¿åº¦: {len(doc.text)}")
            return doc.text
        except Exception as e:
            logger.error(f"æ–‡ä»¶è¯»å–å¤±è´¥: {str(e)}")
            raise Exception(f"æ–‡ä»¶è¯»å–å¤±è´¥: {str(e)}")

    async def get_document_from_llm_files(self, files: list[str]) -> str:
        """è·å–æ–‡ä»¶å†…å®¹ï¼Œæ”¯æŒå›¾ç‰‡ã€æµç¨‹å›¾ã€è¡¨æ ¼ç­‰æ•°æ®"""
        logger.info(f"å¼€å§‹ä½¿ç”¨LLMè§£ææ–‡ä»¶ | æ–‡ä»¶æ•°é‡: {len(files)}")
        extract_contents = ""
        for file in files:
            try:
                logger.debug(f"æ­£åœ¨è§£ææ–‡ä»¶: {file}")
                contents = extract_text_from_llm(file)
                extract_contents += contents + "\n\n--------------\n\n"
                logger.debug(f"æ–‡ä»¶è§£æå®Œæˆ: {file} | å†…å®¹é•¿åº¦: {len(contents)}")
            except Exception as e:
                logger.error(f"æ–‡ä»¶è§£æå¤±è´¥: {file} | é”™è¯¯: {e}")
                extract_contents += (
                    f"æ–‡ä»¶ {file} è§£æå¤±è´¥: {str(e)}\n\n--------------\n\n"
                )

        logger.success(f"LLMæ–‡ä»¶è§£æå®Œæˆ | æ€»å†…å®¹é•¿åº¦: {len(extract_contents)}")
        return extract_contents

    async def generate_testcase_stream(
        self, request: TestCaseRequest
    ) -> AsyncGenerator[TestCaseStreamChunk, None]:
        """
        æµå¼ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹
        ä½¿ç”¨ SingleThreadedAgentRuntime + RoutedAgent å®ç°æ™ºèƒ½ä½“åä½œ
        """
        conversation_id = request.conversation_id or str(uuid.uuid4())
        logger.info(
            f"å¼€å§‹ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹ | å¯¹è¯ID: {conversation_id} | è½®æ¬¡: {request.round_number}"
        )

        if not openai_model_client:
            logger.error("OpenAIæ¨¡å‹å®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
            yield TestCaseStreamChunk(
                content="æ¨¡å‹å®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œæ— æ³•ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹",
                agent_type=AgentType.USER_PROXY,
                agent_name="system",
                conversation_id=conversation_id,
                round_number=request.round_number,
                is_complete=True,
                timestamp=datetime.now(),
            )
            return

        try:
            # åˆ›å»ºè¿è¡Œæ—¶
            logger.info(
                f"[è¿è¡Œæ—¶] åˆ›å»º SingleThreadedAgentRuntime | å¯¹è¯ID: {conversation_id}"
            )
            runtime = SingleThreadedAgentRuntime()

            # æ³¨å†Œæ™ºèƒ½ä½“
            await self._register_agents(runtime, conversation_id)

            # å¯åŠ¨è¿è¡Œæ—¶
            logger.info(f"[è¿è¡Œæ—¶] å¯åŠ¨è¿è¡Œæ—¶ | å¯¹è¯ID: {conversation_id}")
            runtime.start()

            # åˆå§‹åŒ–æ¶ˆæ¯æ”¶é›†
            self.collected_messages[conversation_id] = []

            # æ ¹æ®è½®æ¬¡å‘é€ä¸åŒçš„æ¶ˆæ¯
            if request.round_number == 1:
                # ç¬¬ä¸€è½®ï¼šéœ€æ±‚åˆ†æ
                logger.info(f"[æ¶ˆæ¯å‘é€] å‘é€éœ€æ±‚åˆ†ææ¶ˆæ¯ | å¯¹è¯ID: {conversation_id}")
                content = await self._prepare_task_content(request)
                files_info = (
                    self._prepare_files_info(request.files) if request.files else None
                )

                await runtime.publish_message(
                    RequirementMessage(
                        text_content=content,
                        files=request.files,
                        conversation_id=conversation_id,
                        round_number=request.round_number,
                    ),
                    topic_id=DefaultTopicId(type=requirement_analysis_topic_type),
                )
            else:
                # åç»­è½®æ¬¡ï¼šç”¨æˆ·åé¦ˆ
                logger.info(f"[æ¶ˆæ¯å‘é€] å‘é€ç”¨æˆ·åé¦ˆæ¶ˆæ¯ | å¯¹è¯ID: {conversation_id}")
                if not request.user_feedback:
                    raise ValueError("åç»­è½®æ¬¡éœ€è¦æä¾›ç”¨æˆ·åé¦ˆ")

                # è·å–ä¹‹å‰çš„æµ‹è¯•ç”¨ä¾‹
                previous_testcases = self.active_conversations.get(
                    conversation_id, {}
                ).get("last_testcases", "")

                await runtime.publish_message(
                    TestCaseMessage(
                        source="user_feedback",
                        content=f"ç”¨æˆ·åé¦ˆï¼š{request.user_feedback}\n\nä¹‹å‰çš„æµ‹è¯•ç”¨ä¾‹ï¼š\n{previous_testcases}",
                    ),
                    topic_id=DefaultTopicId(type=user_feedback_topic_type),
                )

            # åˆ›å»ºæµå¼è¾“å‡ºä»»åŠ¡
            logger.info(f"[è¿è¡Œæ—¶] å¼€å§‹æµå¼è¾“å‡ºä»»åŠ¡ | å¯¹è¯ID: {conversation_id}")

            # å¯åŠ¨åå°ä»»åŠ¡ç­‰å¾…å®Œæˆ
            async def wait_for_completion():
                await runtime.stop_when_idle()
                await runtime.close()
                logger.info(
                    f"[è¿è¡Œæ—¶] ä»»åŠ¡å®Œæˆï¼Œè¿è¡Œæ—¶å·²å…³é—­ | å¯¹è¯ID: {conversation_id}"
                )

            # å¯åŠ¨åå°ä»»åŠ¡
            import asyncio

            completion_task = asyncio.create_task(wait_for_completion())

            # å®æ—¶æµå¼è¾“å‡ºæ”¶é›†çš„æ¶ˆæ¯
            last_message_count = 0
            max_wait_time = 60  # æœ€å¤§ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰
            wait_time = 0

            while not completion_task.done() and wait_time < max_wait_time:
                # æ£€æŸ¥æ˜¯å¦æœ‰æ–°æ¶ˆæ¯
                messages = self.collected_messages.get(conversation_id, [])

                # å‘é€æ–°æ¶ˆæ¯
                if len(messages) > last_message_count:
                    for i in range(last_message_count, len(messages)):
                        msg = messages[i]
                        chunk = TestCaseStreamChunk(
                            content=msg["content"],
                            agent_type=AgentType(msg["agent_type"]),
                            agent_name=msg["agent_name"],
                            conversation_id=conversation_id,
                            round_number=request.round_number,
                            timestamp=datetime.fromisoformat(msg["timestamp"]),
                        )
                        logger.debug(
                            f"[æµå¼è¾“å‡º] å‘é€æ¶ˆæ¯å— | æ™ºèƒ½ä½“: {msg['agent_name']} | å¯¹è¯ID: {conversation_id}"
                        )
                        yield chunk

                    last_message_count = len(messages)

                # çŸ­æš‚ç­‰å¾…
                await asyncio.sleep(0.1)
                wait_time += 0.1

            # ç­‰å¾…ä»»åŠ¡å®Œæˆ
            if not completion_task.done():
                logger.warning(
                    f"[è¿è¡Œæ—¶] ç­‰å¾…è¶…æ—¶ï¼Œå¼ºåˆ¶å®Œæˆ | å¯¹è¯ID: {conversation_id}"
                )
                completion_task.cancel()
            else:
                await completion_task

            # å‘é€å‰©ä½™æ¶ˆæ¯ï¼ˆå¦‚æœæœ‰ï¼‰
            messages = self.collected_messages.get(conversation_id, [])
            if len(messages) > last_message_count:
                for i in range(last_message_count, len(messages)):
                    msg = messages[i]
                    chunk = TestCaseStreamChunk(
                        content=msg["content"],
                        agent_type=AgentType(msg["agent_type"]),
                        agent_name=msg["agent_name"],
                        conversation_id=conversation_id,
                        round_number=request.round_number,
                        timestamp=datetime.fromisoformat(msg["timestamp"]),
                    )
                    logger.debug(
                        f"[æµå¼è¾“å‡º] å‘é€å‰©ä½™æ¶ˆæ¯å— | æ™ºèƒ½ä½“: {msg['agent_name']} | å¯¹è¯ID: {conversation_id}"
                    )
                    yield chunk

            # å‘é€å®Œæˆä¿¡å·
            final_chunk = TestCaseStreamChunk(
                content="",
                agent_type=AgentType.USER_PROXY,
                agent_name="system",
                conversation_id=conversation_id,
                round_number=request.round_number,
                is_complete=True,
                timestamp=datetime.now(),
            )
            logger.success(
                f"[ä»»åŠ¡å®Œæˆ] æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå®Œæˆ | å¯¹è¯ID: {conversation_id} | æ€»æ¶ˆæ¯æ•°: {len(messages)}"
            )
            yield final_chunk

        except Exception as e:
            logger.error(f"ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹å¤±è´¥ | å¯¹è¯ID: {conversation_id} | é”™è¯¯: {e}")
            error_chunk = TestCaseStreamChunk(
                content=f"ç”Ÿæˆå¤±è´¥: {str(e)}",
                agent_type=AgentType.USER_PROXY,
                agent_name="system",
                conversation_id=conversation_id,
                round_number=request.round_number,
                is_complete=True,
                timestamp=datetime.now(),
            )
            yield error_chunk

    async def _register_agents(
        self, runtime: SingleThreadedAgentRuntime, conversation_id: str
    ):
        """æ³¨å†Œæ™ºèƒ½ä½“åˆ°è¿è¡Œæ—¶"""
        logger.info(f"[æ™ºèƒ½ä½“æ³¨å†Œ] å¼€å§‹æ³¨å†Œæ™ºèƒ½ä½“ | å¯¹è¯ID: {conversation_id}")

        # è·å–æ¨¡å‹å®¢æˆ·ç«¯
        model_client = openai_model_client
        if not model_client:
            logger.error("æ¨¡å‹å®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
            return

        # æ³¨å†Œéœ€æ±‚åˆ†ææ™ºèƒ½ä½“
        await RequirementAnalysisAgent.register(
            runtime,
            requirement_analysis_topic_type,
            lambda: RequirementAnalysisAgent(model_client),
        )

        # æ³¨å†Œæµ‹è¯•ç”¨ä¾‹ç”Ÿæˆæ™ºèƒ½ä½“
        await TestCaseGenerationAgent.register(
            runtime,
            testcase_generation_topic_type,
            lambda: TestCaseGenerationAgent(model_client),
        )

        # æ³¨å†Œç”¨æˆ·åé¦ˆå¤„ç†æ™ºèƒ½ä½“
        await UserFeedbackAgent.register(
            runtime,
            user_feedback_topic_type,
            lambda: UserFeedbackAgent(model_client),
        )

        # æ³¨å†Œæµ‹è¯•ç”¨ä¾‹è¯„å®¡æ™ºèƒ½ä½“
        await TestCaseReviewAgent.register(
            runtime,
            testcase_review_topic_type,
            lambda: TestCaseReviewAgent(model_client),
        )

        # æ³¨å†Œç»“æœæ”¶é›†å™¨ - ä½¿ç”¨ClosureAgent
        async def collect_result(
            _agent: ClosureContext, message: ResponseMessage, ctx: MessageContext
        ) -> None:
            """æ”¶é›†æ™ºèƒ½ä½“ç»“æœ"""
            if conversation_id not in self.collected_messages:
                self.collected_messages[conversation_id] = []

            # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
            result_dict = {
                "content": message.content,
                "agent_type": "unknown",
                "agent_name": message.source,
                "conversation_id": conversation_id,
                "round_number": 1,
                "timestamp": datetime.now().isoformat(),
                "is_complete": message.is_final,
            }

            self.collected_messages[conversation_id].append(result_dict)
            logger.debug(
                f"[ç»“æœæ”¶é›†] æ¶ˆæ¯å·²æ”¶é›† | æ™ºèƒ½ä½“: {message.source} | å¯¹è¯ID: {conversation_id}"
            )

        await ClosureAgent.register_closure(
            runtime,
            "collect_result",
            collect_result,
            subscriptions=lambda: [
                TypeSubscription(
                    topic_type=task_result_topic_type, agent_type="collect_result"
                )
            ],
        )

        logger.success(f"[æ™ºèƒ½ä½“æ³¨å†Œ] æ‰€æœ‰æ™ºèƒ½ä½“æ³¨å†Œå®Œæˆ | å¯¹è¯ID: {conversation_id}")

    def _prepare_files_info(self, files: List[FileUpload]) -> List[dict]:
        """å‡†å¤‡æ–‡ä»¶ä¿¡æ¯"""
        if not files:
            return []

        files_info = []
        for file in files:
            file_info = {
                "filename": file.filename,
                "content_type": file.content_type,
                "size": file.size,
            }

            # å¦‚æœæ˜¯æ–‡æœ¬æ–‡ä»¶ï¼Œå°è¯•è§£ç å†…å®¹
            if file.content_type.startswith("text/"):
                try:
                    content = base64.b64decode(file.content).decode("utf-8")
                    file_info["content"] = content[:1000]  # é™åˆ¶é•¿åº¦
                except Exception as e:
                    logger.warning(f"è§£ç æ–‡ä»¶å†…å®¹å¤±è´¥: {e}")
                    file_info["content"] = "æ— æ³•è§£ç æ–‡ä»¶å†…å®¹"

            files_info.append(file_info)

        return files_info

    async def _prepare_task_content(self, request: TestCaseRequest) -> str:
        """
        å‡†å¤‡ä»»åŠ¡å†…å®¹ï¼ŒåŒ…æ‹¬æ–‡æœ¬å†…å®¹å’Œæ–‡ä»¶è§£æ
        """
        conversation_id = request.conversation_id or "unknown"
        logger.info(
            f"å¼€å§‹å‡†å¤‡ä»»åŠ¡å†…å®¹ | å¯¹è¯ID: {conversation_id} | è½®æ¬¡: {request.round_number}"
        )
        content_parts = []

        # å¤„ç†æ–‡æœ¬å†…å®¹
        if request.text_content:
            content_parts.append(f"ç”¨æˆ·éœ€æ±‚æè¿°ï¼š\n{request.text_content}")
            logger.debug(
                f"æ·»åŠ æ–‡æœ¬å†…å®¹ | å¯¹è¯ID: {conversation_id} | é•¿åº¦: {len(request.text_content)}"
            )

        # å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶
        if request.files:
            logger.info(
                f"å¼€å§‹å¤„ç†ä¸Šä¼ æ–‡ä»¶ | å¯¹è¯ID: {conversation_id} | æ–‡ä»¶æ•°é‡: {len(request.files)}"
            )

            # ä¿å­˜æ–‡ä»¶åˆ°ä¸´æ—¶ä½ç½®å¹¶è§£æ
            file_paths = []
            for file in request.files:
                try:
                    # è§£ç æ–‡ä»¶å†…å®¹
                    file_content = base64.b64decode(file.content)

                    # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
                    temp_filename = f"temp_{uuid.uuid4()}_{file.filename}"
                    with open(temp_filename, "wb") as f:
                        f.write(file_content)

                    file_paths.append(temp_filename)
                    logger.debug(
                        f"æ–‡ä»¶ä¿å­˜æˆåŠŸ | å¯¹è¯ID: {conversation_id} | {file.filename} -> {temp_filename}"
                    )

                except Exception as e:
                    logger.error(
                        f"æ–‡ä»¶å¤„ç†å¤±è´¥ | å¯¹è¯ID: {conversation_id} | {file.filename} | é”™è¯¯: {e}"
                    )
                    content_parts.append(f"æ–‡ä»¶ {file.filename} å¤„ç†å¤±è´¥: {str(e)}")

            # è§£ææ–‡ä»¶å†…å®¹
            if file_paths:
                try:
                    # å°è¯•ä½¿ç”¨ llama_index è§£æ
                    file_content = await self.get_document_from_files(file_paths)
                    content_parts.append(f"æ–‡ä»¶å†…å®¹ï¼š\n{file_content}")
                    logger.success(
                        f"æ–‡ä»¶è§£æå®Œæˆ | å¯¹è¯ID: {conversation_id} | å†…å®¹é•¿åº¦: {len(file_content)}"
                    )
                except Exception as e:
                    logger.warning(
                        f"llama_index è§£æå¤±è´¥ï¼Œå°è¯•ä½¿ç”¨ LLM è§£æ | å¯¹è¯ID: {conversation_id} | é”™è¯¯: {e}"
                    )
                    try:
                        # ä½¿ç”¨ LLM è§£æ
                        file_content = await self.get_document_from_llm_files(
                            file_paths
                        )
                        content_parts.append(f"æ–‡ä»¶å†…å®¹ï¼ˆLLMè§£æï¼‰ï¼š\n{file_content}")
                        logger.success(
                            f"LLMæ–‡ä»¶è§£æå®Œæˆ | å¯¹è¯ID: {conversation_id} | å†…å®¹é•¿åº¦: {len(file_content)}"
                        )
                    except Exception as e2:
                        logger.error(
                            f"æ–‡ä»¶è§£æå®Œå…¨å¤±è´¥ | å¯¹è¯ID: {conversation_id} | é”™è¯¯: {e2}"
                        )
                        content_parts.append(f"æ–‡ä»¶è§£æå¤±è´¥: {str(e2)}")

                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                for temp_file in file_paths:
                    try:
                        import os

                        os.remove(temp_file)
                        logger.debug(
                            f"ä¸´æ—¶æ–‡ä»¶æ¸…ç†å®Œæˆ | å¯¹è¯ID: {conversation_id} | æ–‡ä»¶: {temp_file}"
                        )
                    except Exception as e:
                        logger.warning(
                            f"ä¸´æ—¶æ–‡ä»¶æ¸…ç†å¤±è´¥ | å¯¹è¯ID: {conversation_id} | æ–‡ä»¶: {temp_file} | é”™è¯¯: {e}"
                        )

        # å¤„ç†ç”¨æˆ·åé¦ˆï¼ˆåç»­è½®æ¬¡ï¼‰
        if request.round_number > 1 and request.user_feedback:
            content_parts.append(f"ç”¨æˆ·åé¦ˆï¼š\n{request.user_feedback}")
            logger.debug(
                f"æ·»åŠ ç”¨æˆ·åé¦ˆ | å¯¹è¯ID: {conversation_id} | é•¿åº¦: {len(request.user_feedback)}"
            )

        task_content = "\n\n".join(content_parts)
        logger.success(
            f"ä»»åŠ¡å†…å®¹å‡†å¤‡å®Œæˆ | å¯¹è¯ID: {conversation_id} | æ€»é•¿åº¦: {len(task_content)}"
        )
        return task_content

    def _get_testcase_generator_prompt(self) -> str:
        """
        è·å–æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆæ™ºèƒ½ä½“çš„ç³»ç»Ÿæç¤ºè¯
        """
        return """
ä½ æ˜¯ä¸€åæ‹¥æœ‰è¶…è¿‡10å¹´ç»éªŒçš„èµ„æ·±è½¯ä»¶æµ‹è¯•æ¶æ„å¸ˆï¼Œç²¾é€šå„ç§æµ‹è¯•æ–¹æ³•è®ºï¼ˆå¦‚ï¼šç­‰ä»·ç±»åˆ’åˆ†ã€è¾¹ç•Œå€¼åˆ†æã€å› æœå›¾ã€åœºæ™¯æ³•ç­‰ï¼‰ï¼Œå¹¶ä¸”å¯¹ç”¨æˆ·ä½“éªŒå’Œç³»ç»Ÿæ€§èƒ½æœ‰æ·±åˆ»çš„ç†è§£ã€‚

ä½ çš„ä»»åŠ¡æ˜¯ä¸ºæ¥æ”¶åˆ°çš„åŠŸèƒ½éœ€æ±‚ï¼Œè®¾è®¡ä¸€ä»½ä¸“ä¸šã€å…¨é¢ã€ä¸”æ˜“äºæ‰§è¡Œçš„é«˜è´¨é‡æµ‹è¯•ç”¨ä¾‹ã€‚

æµ‹è¯•è¦æ±‚ï¼š
1. å…¨é¢æ€§ï¼šè¦†ç›–åŠŸèƒ½æµ‹è¯•ã€UI/UXæµ‹è¯•ã€å…¼å®¹æ€§æµ‹è¯•ã€å¼‚å¸¸/è¾¹ç•Œæµ‹è¯•ã€åœºæ™¯ç»„åˆæµ‹è¯•
2. ä¸“ä¸šæ€§ï¼šæ¯ä¸ªæµ‹è¯•ç”¨ä¾‹éƒ½åº”éµå¾ªæ ‡å‡†æ ¼å¼ï¼Œæ­¥éª¤æ¸…æ™°ï¼Œé¢„æœŸç»“æœæ˜ç¡®
3. è¾“å‡ºæ ¼å¼ï¼šä½¿ç”¨Markdownè¡¨æ ¼æ ¼å¼ï¼ŒåŒ…å«ç”¨ä¾‹IDã€æ¨¡å—ã€ä¼˜å…ˆçº§ã€æµ‹è¯•ç±»å‹ã€ç”¨ä¾‹æ ‡é¢˜ã€å‰ç½®æ¡ä»¶ã€æµ‹è¯•æ­¥éª¤ã€é¢„æœŸç»“æœ

è¯·åŸºäºæä¾›çš„éœ€æ±‚ï¼Œç”Ÿæˆé«˜è´¨é‡çš„æµ‹è¯•ç”¨ä¾‹ã€‚å¦‚æœç”¨æˆ·æå‡ºä¿®æ”¹æ„è§ï¼Œè¯·æ ¹æ®åé¦ˆè¿›è¡Œä¼˜åŒ–ã€‚

å½“ç”¨æˆ·å¯¹æµ‹è¯•ç”¨ä¾‹æ»¡æ„æ—¶ï¼Œè¯·ç­‰å¾…ç”¨æˆ·å›å¤"åŒæ„"æˆ–"APPROVE"æ¥ç¡®è®¤ã€‚
        """


# æ™ºèƒ½ä½“å®ç° - ä»¿ç…§examples/agent/testcase_agents.py


@type_subscription(topic_type=requirement_analysis_topic_type)
class RequirementAnalysisAgent(RoutedAgent):
    """éœ€æ±‚åˆ†ææ™ºèƒ½ä½“ - ä»¿ç…§examples"""

    def __init__(self, model_client) -> None:
        super().__init__(description="éœ€æ±‚åˆ†ææ™ºèƒ½ä½“")
        self._model_client = model_client
        self._prompt = """
ä½ æ˜¯ä¸€ä½èµ„æ·±çš„è½¯ä»¶éœ€æ±‚åˆ†æå¸ˆï¼Œæ‹¥æœ‰è¶…è¿‡10å¹´çš„éœ€æ±‚åˆ†æå’Œè½¯ä»¶æµ‹è¯•ç»éªŒã€‚

ä½ çš„ä»»åŠ¡æ˜¯ï¼š
1. ä»”ç»†åˆ†æç”¨æˆ·æä¾›çš„å†…å®¹ï¼ˆæ–‡æœ¬ã€æ–‡ä»¶ç­‰ï¼‰
2. è¯†åˆ«å‡ºæ ¸å¿ƒçš„åŠŸèƒ½éœ€æ±‚å’Œä¸šåŠ¡åœºæ™¯
3. æå–å…³é”®çš„ä¸šåŠ¡è§„åˆ™å’Œçº¦æŸæ¡ä»¶
4. æ•´ç†å‡ºæ¸…æ™°ã€ç»“æ„åŒ–çš„éœ€æ±‚æè¿°

è¯·ç”¨ä¸“ä¸šã€æ¸…æ™°çš„è¯­è¨€è¾“å‡ºåˆ†æç»“æœï¼Œä¸ºåç»­çš„æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆæä¾›å‡†ç¡®çš„éœ€æ±‚åŸºç¡€ã€‚
        """

    @message_handler
    async def handle_requirement_analysis(
        self, message: RequirementMessage, ctx: MessageContext
    ) -> None:
        """å¤„ç†éœ€æ±‚åˆ†æ"""
        logger.info(f"[éœ€æ±‚åˆ†æ] å¼€å§‹éœ€æ±‚åˆ†æ | å¯¹è¯ID: {message.conversation_id}")

        if not self._model_client:
            logger.error("æ¨¡å‹å®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
            return

        agent = AssistantAgent(
            name="requirement_analyst",
            model_client=self._model_client,
            system_message=self._prompt,
        )

        # æ„å»ºåˆ†æä»»åŠ¡
        task_content = f"è¯·åˆ†æä»¥ä¸‹å†…å®¹çš„åŠŸèƒ½éœ€æ±‚ï¼š\n\n{message.text_content}"
        if message.files:
            task_content += f"\n\næ–‡ä»¶ä¿¡æ¯ï¼š\n"
            for file_info in message.files:
                task_content += f"- {file_info.filename}: {file_info.content_type}\n"

        try:
            # æ‰§è¡Œéœ€æ±‚åˆ†æ
            logger.info(
                f"[éœ€æ±‚åˆ†æ] å¼€å§‹æ‰§è¡Œåˆ†æä»»åŠ¡ | å¯¹è¯ID: {message.conversation_id}"
            )
            result = await agent.run(task=task_content)
            requirements = str(result)

            logger.success(
                f"[éœ€æ±‚åˆ†æ] éœ€æ±‚åˆ†æå®Œæˆ | å¯¹è¯ID: {message.conversation_id}"
            )

            # å‘é€ç»“æœåˆ°æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆæ™ºèƒ½ä½“
            await self.publish_message(
                TestCaseMessage(
                    source="requirement_analyst",
                    content=requirements,
                ),
                topic_id=TopicId(
                    type=testcase_generation_topic_type, source=self.id.key
                ),
            )

            # å‘é€ç»“æœåˆ°æ”¶é›†å™¨
            await self.publish_message(
                ResponseMessage(
                    source="requirement_analyst",
                    content=requirements,
                    is_final=False,
                ),
                topic_id=TopicId(type=task_result_topic_type, source=self.id.key),
            )

        except Exception as e:
            logger.error(
                f"[éœ€æ±‚åˆ†æ] éœ€æ±‚åˆ†æå¤±è´¥ | å¯¹è¯ID: {message.conversation_id} | é”™è¯¯: {e}"
            )


@type_subscription(topic_type=testcase_generation_topic_type)
class TestCaseGenerationAgent(RoutedAgent):
    """æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆæ™ºèƒ½ä½“ - ä»¿ç…§examples"""

    def __init__(self, model_client, input_func=None):
        super().__init__(description="æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆæ™ºèƒ½ä½“")
        self._model_client = model_client
        self.input_func = input_func
        self._prompt = """
ä½ æ˜¯ä¸€åæ‹¥æœ‰è¶…è¿‡10å¹´ç»éªŒçš„èµ„æ·±è½¯ä»¶æµ‹è¯•æ¶æ„å¸ˆï¼Œç²¾é€šå„ç§æµ‹è¯•æ–¹æ³•è®ºï¼ˆå¦‚ï¼šç­‰ä»·ç±»åˆ’åˆ†ã€è¾¹ç•Œå€¼åˆ†æã€å› æœå›¾ã€åœºæ™¯æ³•ç­‰ï¼‰ï¼Œå¹¶ä¸”å¯¹ç”¨æˆ·ä½“éªŒå’Œç³»ç»Ÿæ€§èƒ½æœ‰æ·±åˆ»çš„ç†è§£ã€‚

ä½ çš„ä»»åŠ¡æ˜¯ä¸ºæ¥æ”¶åˆ°çš„åŠŸèƒ½éœ€æ±‚ï¼Œè®¾è®¡ä¸€ä»½ä¸“ä¸šã€å…¨é¢ã€ä¸”æ˜“äºæ‰§è¡Œçš„é«˜è´¨é‡æµ‹è¯•ç”¨ä¾‹ã€‚

æµ‹è¯•è¦æ±‚ï¼š
1. å…¨é¢æ€§ï¼šè¦†ç›–åŠŸèƒ½æµ‹è¯•ã€UI/UXæµ‹è¯•ã€å…¼å®¹æ€§æµ‹è¯•ã€å¼‚å¸¸/è¾¹ç•Œæµ‹è¯•ã€åœºæ™¯ç»„åˆæµ‹è¯•
2. ä¸“ä¸šæ€§ï¼šæ¯ä¸ªæµ‹è¯•ç”¨ä¾‹éƒ½åº”éµå¾ªæ ‡å‡†æ ¼å¼ï¼Œæ­¥éª¤æ¸…æ™°ï¼Œé¢„æœŸç»“æœæ˜ç¡®
3. è¾“å‡ºæ ¼å¼ï¼šä½¿ç”¨Markdownè¡¨æ ¼æ ¼å¼ï¼ŒåŒ…å«ç”¨ä¾‹IDã€æ¨¡å—ã€ä¼˜å…ˆçº§ã€æµ‹è¯•ç±»å‹ã€ç”¨ä¾‹æ ‡é¢˜ã€å‰ç½®æ¡ä»¶ã€æµ‹è¯•æ­¥éª¤ã€é¢„æœŸç»“æœ

è¯·åŸºäºæä¾›çš„éœ€æ±‚ï¼Œç”Ÿæˆé«˜è´¨é‡çš„æµ‹è¯•ç”¨ä¾‹ã€‚
        """

    @message_handler
    async def handle_testcase_generation(
        self, message: TestCaseMessage, ctx: MessageContext
    ) -> None:
        """å¤„ç†æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆ"""
        logger.info(f"[æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆ] å¼€å§‹ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹ | æ¥æº: {message.source}")

        if not self._model_client:
            logger.error("æ¨¡å‹å®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
            return

        # å‘é€åˆ°å‰ç«¯æç¤º
        await self.publish_message(
            ResponseMessage(
                source="testcase_generator",
                content="æ”¶åˆ°éœ€æ±‚åˆ†æç»“æœï¼Œå¼€å§‹ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹...",
            ),
            topic_id=TopicId(type=task_result_topic_type, source=self.id.key),
        )

        testcase_generator_agent = AssistantAgent(
            name="testcase_generator_agent",
            model_client=self._model_client,
            system_message=self._prompt,
            model_client_stream=True,
        )

        # éœ€è¦ç”¨æˆ·å¯¹ç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹æå‡ºä¿®æ”¹å»ºè®®
        if self.input_func:
            user_proxy = UserProxyAgent(name="user_proxy", input_func=self.input_func)
            from autogen_agentchat.conditions import TextMentionTermination
            from autogen_agentchat.teams import RoundRobinGroupChat

            termination_en = TextMentionTermination("APPROVE")
            termination_zh = TextMentionTermination("åŒæ„")
            team = RoundRobinGroupChat(
                [testcase_generator_agent, user_proxy],
                termination_condition=termination_en | termination_zh,
            )

            stream = team.run_stream(
                task=f"åŸºäºä»¥ä¸‹éœ€æ±‚ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹ï¼š\n\n{message.content}"
            )
            testcase_content = ""

            async for msg in stream:
                # æ¨¡æ‹Ÿæµå¼è¾“å‡º
                if isinstance(msg, ModelClientStreamingChunkEvent):
                    await self.publish_message(
                        ResponseMessage(
                            source="testcase_generator", content=msg.content
                        ),
                        topic_id=TopicId(
                            type=task_result_topic_type, source=self.id.key
                        ),
                    )
                    continue

                # ç»Ÿè®¡æµ‹è¯•ç”¨ä¾‹æ›´æ–°æ¬¡æ•°å¹¶ä¿å­˜ç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹
                if isinstance(msg, TextMessage):
                    if msg.source == "testcase_generator_agent":
                        testcase_content = msg.content
                        continue

                # ç­‰å¾…ç”¨æˆ·è¾“å…¥å¯¹æµ‹è¯•ç”¨ä¾‹çš„ä¿®æ”¹å»ºè®®
                if (
                    isinstance(msg, UserInputRequestedEvent)
                    and msg.source == "user_proxy"
                ):
                    await self.publish_message(
                        ResponseMessage(
                            source=msg.source, content="è¯·è¾“å…¥ä¿®æ”¹å»ºè®®æˆ–è€…ç›´æ¥ç‚¹å‡»åŒæ„"
                        ),
                        topic_id=TopicId(
                            type=task_result_topic_type, source=self.id.key
                        ),
                    )
                    continue

            # å‘é€ç»™ä¸‹ä¸€ä¸ªæ™ºèƒ½ä½“
            await self.publish_message(
                TestCaseMessage(source=self.id.type, content=testcase_content),
                topic_id=TopicId(testcase_review_topic_type, source=self.id.key),
            )
        else:
            # ç”¨æˆ·ä¸å‚ä¸ç”¨ä¾‹ä¿®æ”¹
            result = await testcase_generator_agent.run(
                task=f"åŸºäºä»¥ä¸‹éœ€æ±‚ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹ï¼š\n\n{message.content}"
            )
            testcase_content = str(result)

            # å‘é€åˆ°å‰ç«¯æç¤º
            await self.publish_message(
                ResponseMessage(source="testcase_generator", content=testcase_content),
                topic_id=TopicId(type=task_result_topic_type, source=self.id.key),
            )

            # å‘é€ç»™ä¸‹ä¸€ä¸ªæ™ºèƒ½ä½“
            await self.publish_message(
                TestCaseMessage(source=self.id.type, content=testcase_content),
                topic_id=TopicId(testcase_review_topic_type, source=self.id.key),
            )


@type_subscription(topic_type=user_feedback_topic_type)
class UserFeedbackAgent(RoutedAgent):
    """ç”¨æˆ·åé¦ˆå¤„ç†æ™ºèƒ½ä½“"""

    def __init__(self, model_client):
        super().__init__(description="ç”¨æˆ·åé¦ˆå¤„ç†æ™ºèƒ½ä½“")
        self._model_client = model_client
        self._prompt = """
ä½ æ˜¯ä¸€åæ‹¥æœ‰è¶…è¿‡15å¹´è½¯ä»¶è´¨é‡ä¿è¯ï¼ˆSQAï¼‰ç»éªŒçš„æµ‹è¯•ä¸»ç®¡ï¼ˆTest Leadï¼‰ã€‚ä½ ä»¥ä¸¥è°¨ã€ç»†è‡´å’Œæ³¨é‡ç»†èŠ‚è€Œé—»åã€‚

ä½ çš„ä»»åŠ¡æ˜¯ï¼š
1. ä»”ç»†åˆ†æç”¨æˆ·å¯¹æµ‹è¯•ç”¨ä¾‹çš„åé¦ˆæ„è§
2. è¯†åˆ«éœ€è¦æ”¹è¿›çš„å…·ä½“ç‚¹
3. åŸºäºåé¦ˆé‡æ–°ä¼˜åŒ–å’Œå®Œå–„æµ‹è¯•ç”¨ä¾‹
4. ç¡®ä¿ä¿®æ”¹åçš„æµ‹è¯•ç”¨ä¾‹æ›´ç¬¦åˆç”¨æˆ·çš„æœŸæœ›å’Œå®é™…éœ€æ±‚

è¯·æ ¹æ®ç”¨æˆ·åé¦ˆï¼Œå¯¹æµ‹è¯•ç”¨ä¾‹è¿›è¡Œé’ˆå¯¹æ€§çš„æ”¹è¿›å’Œä¼˜åŒ–ã€‚
        """

    @message_handler
    async def handle_user_feedback(
        self, message: TestCaseMessage, ctx: MessageContext
    ) -> None:
        """å¤„ç†ç”¨æˆ·åé¦ˆ"""
        logger.info(f"[ç”¨æˆ·åé¦ˆå¤„ç†] å¼€å§‹å¤„ç†ç”¨æˆ·åé¦ˆ | æ¥æº: {message.source}")

        if not self._model_client:
            logger.error("æ¨¡å‹å®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
            return

        agent = AssistantAgent(
            name="feedback_processor",
            model_client=self._model_client,
            system_message=self._prompt,
            model_client_stream=True,
        )

        task_content = f"è¯·æ ¹æ®ç”¨æˆ·åé¦ˆï¼Œæ”¹è¿›å’Œä¼˜åŒ–ä»¥ä¸‹æµ‹è¯•ç”¨ä¾‹ï¼š\n\n{message.content}"

        try:
            logger.info(f"[ç”¨æˆ·åé¦ˆå¤„ç†] å¼€å§‹æ‰§è¡Œåé¦ˆå¤„ç†ä»»åŠ¡ | æ¥æº: {message.source}")
            result = await agent.run(task=task_content)
            improved_testcases = str(result)

            logger.success(f"[ç”¨æˆ·åé¦ˆå¤„ç†] åé¦ˆå¤„ç†å®Œæˆ | æ¥æº: {message.source}")

            # å‘é€ç»“æœåˆ°æ”¶é›†å™¨
            await self.publish_message(
                ResponseMessage(
                    source="feedback_processor",
                    content=improved_testcases,
                    is_final=True,
                ),
                topic_id=TopicId(type=task_result_topic_type, source=self.id.key),
            )

        except Exception as e:
            logger.error(
                f"[ç”¨æˆ·åé¦ˆå¤„ç†] åé¦ˆå¤„ç†å¤±è´¥ | æ¥æº: {message.source} | é”™è¯¯: {e}"
            )


# ç§»é™¤æ—§çš„ResultCollectorAgentï¼Œå› ä¸ºæˆ‘ä»¬ä½¿ç”¨ClosureAgentæ¥æ”¶é›†ç»“æœ


@type_subscription(topic_type=testcase_review_topic_type)
class TestCaseReviewAgent(RoutedAgent):
    """æµ‹è¯•ç”¨ä¾‹è¯„å®¡æ™ºèƒ½ä½“ - ä»¿ç…§examples"""

    def __init__(self, model_client):
        super().__init__(description="æµ‹è¯•ç”¨ä¾‹è¯„å®¡æ™ºèƒ½ä½“")
        self._model_client = model_client
        self._prompt = """
ä½ æ˜¯èµ„æ·±æµ‹è¯•ç”¨ä¾‹è¯„å®¡ä¸“å®¶ï¼Œå…³æ³¨ç”¨ä¾‹è´¨é‡ä¸æµ‹è¯•è¦†ç›–æœ‰æ•ˆæ€§ã€‚è¯·æ ¹æ®ç”¨æˆ·æä¾›çš„æµ‹è¯•ç”¨ä¾‹è¿›è¡Œè¯„å®¡ï¼Œç»™å‡ºè¯„å®¡æ„è§åŠè¯„å®¡æŠ¥å‘Šï¼Œmarkdownæ ¼å¼è¾“å‡º

## 1. è¯„å®¡é‡ç‚¹
1. éœ€æ±‚è¦†ç›–åº¦ï¼šç¡®ä¿æ¯ä¸ªéœ€æ±‚ç‚¹éƒ½æœ‰å¯¹åº”æµ‹è¯•ç”¨ä¾‹
2. æµ‹è¯•æ·±åº¦ï¼šæ­£å¸¸æµ/è¾¹ç•Œ/å¼‚å¸¸æµå…¨é¢è¦†ç›–
3. ç”¨ä¾‹å¯æ‰§è¡Œæ€§ï¼šæ­¥éª¤æ¸…æ™°ã€æ•°æ®æ˜ç¡®

## 2. è¾“å‡ºæ ¼å¼
### æµ‹è¯•ç”¨ä¾‹è¯„å®¡æŠ¥å‘Š
#### 1. æ¦‚è¿°
- è¯„å®¡æ—¥æœŸ: [date]
- ç”¨ä¾‹æ€»æ•°: [number]
- è¦†ç›–ç‡: [percentage]

#### 2. é—®é¢˜åˆ†ç±»
**ğŸ”´ ä¸¥é‡é—®é¢˜**
- [é—®é¢˜æè¿°] @[ç”¨ä¾‹ç¼–å·]
- [æ”¹è¿›å»ºè®®]

**ğŸŸ¡ å»ºè®®ä¼˜åŒ–**
- [é—®é¢˜æè¿°] @[ç”¨ä¾‹ç¼–å·]
- [ä¼˜åŒ–æ–¹æ¡ˆ]

#### 3. æ€»ç»“å»ºè®®
- å…³é”®é£é™©ç‚¹: [é£é™©æè¿°]
- åç»­è¡ŒåŠ¨è®¡åˆ’: [action items]
        """

    @message_handler
    async def handle_testcase_review(
        self, message: TestCaseMessage, ctx: MessageContext
    ) -> None:
        """å¤„ç†æµ‹è¯•ç”¨ä¾‹è¯„å®¡"""
        logger.info(f"[æµ‹è¯•ç”¨ä¾‹è¯„å®¡] å¼€å§‹è¯„å®¡æµ‹è¯•ç”¨ä¾‹ | æ¥æº: {message.source}")

        if not self._model_client:
            logger.error("æ¨¡å‹å®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
            return

        agent = AssistantAgent(
            name="testcase_review_agent",
            model_client=self._model_client,
            system_message=self._prompt,
            model_client_stream=True,
        )

        task = "è¯·å¯¹å¦‚ä¸‹æµ‹è¯•ç”¨ä¾‹è¿›è¡Œè¯„å®¡ï¼Œå¹¶è¾“å‡ºè§„èŒƒçš„è¯„å®¡æŠ¥å‘Šï¼š\n" + message.content
        review_report = ""

        stream = agent.run_stream(task=task)
        async for msg in stream:
            if isinstance(msg, ModelClientStreamingChunkEvent):
                # æµå¼è¾“å‡ºç»“æœåˆ°å‰ç«¯ç•Œé¢
                await self.publish_message(
                    ResponseMessage(source="testcase_reviewer", content=msg.content),
                    topic_id=TopicId(type=task_result_topic_type, source=self.id.key),
                )
                continue
            if isinstance(msg, TaskResult):
                review_report = msg.messages[-1].content
                continue

        # å‘é€æœ€ç»ˆç»“æœ
        final_content = f"--æµ‹è¯•ç”¨ä¾‹å¼€å§‹--\n{message.content}\n--æµ‹è¯•ç”¨ä¾‹ç»“æŸ--\n--è¯„å®¡æŠ¥å‘Šå¼€å§‹--\n{review_report}\n--è¯„å®¡æŠ¥å‘Šç»“æŸ--"
        await self.publish_message(
            ResponseMessage(
                source="testcase_reviewer", content=final_content, is_final=True
            ),
            topic_id=TopicId(type=task_result_topic_type, source=self.id.key),
        )


# å¯åŠ¨è¿è¡Œæ—¶å‡½æ•° - ä»¿ç…§examples/agent/testcase_agents.py
async def start_runtime(
    requirement: RequirementMessage, collect_result, user_input_func=None
):
    """å¯åŠ¨è¿è¡Œæ—¶ - ä»¿ç…§examples"""
    logger.info(f"[å¯åŠ¨è¿è¡Œæ—¶] å¼€å§‹å¯åŠ¨è¿è¡Œæ—¶ | å¯¹è¯ID: {requirement.conversation_id}")

    # åˆ›å»ºè¿è¡Œæ—¶
    runtime = SingleThreadedAgentRuntime()

    # è·å–æ¨¡å‹å®¢æˆ·ç«¯
    model_client = openai_model_client
    if not model_client:
        logger.error("æ¨¡å‹å®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
        return

    # æ³¨å†Œæ™ºèƒ½ä½“
    await RequirementAnalysisAgent.register(
        runtime,
        requirement_analysis_topic_type,
        lambda: RequirementAnalysisAgent(model_client),
    )

    await TestCaseGenerationAgent.register(
        runtime,
        testcase_generation_topic_type,
        lambda: TestCaseGenerationAgent(model_client, user_input_func),
    )

    await TestCaseReviewAgent.register(
        runtime, testcase_review_topic_type, lambda: TestCaseReviewAgent(model_client)
    )

    # æ³¨å†Œç»“æœæ”¶é›†å™¨ - ä½¿ç”¨ClosureAgent
    await ClosureAgent.register_closure(
        runtime,
        "collect_result",
        collect_result,
        subscriptions=lambda: [
            TypeSubscription(
                topic_type=task_result_topic_type, agent_type="collect_result"
            )
        ],
    )

    # å¯åŠ¨è¿è¡Œæ—¶
    runtime.start()

    # å‘é€åˆå§‹éœ€æ±‚æ¶ˆæ¯
    await runtime.publish_message(
        requirement, topic_id=DefaultTopicId(type=requirement_analysis_topic_type)
    )

    # ç­‰å¾…å®Œæˆ
    await runtime.stop_when_idle()
    await runtime.close()

    logger.success(f"[å¯åŠ¨è¿è¡Œæ—¶] è¿è¡Œæ—¶å®Œæˆ | å¯¹è¯ID: {requirement.conversation_id}")


# å…¨å±€æœåŠ¡å®ä¾‹
testcase_service = TestCaseService()
