"""
LLMæ¨¡å‹å®¢æˆ·ç«¯é…ç½®
æä¾›ç»Ÿä¸€çš„OpenAIæ¨¡å‹å®¢æˆ·ç«¯å®ä¾‹ï¼Œä¾›æ•´ä¸ªåº”ç”¨ä½¿ç”¨
"""

from autogen_core.models import ModelFamily
from autogen_ext.models.openai import OpenAIChatCompletionClient
from loguru import logger

from backend.conf.config import settings


def create_openai_model_client() -> OpenAIChatCompletionClient:
    """
    åˆ›å»ºOpenAIæ¨¡å‹å®¢æˆ·ç«¯å®ä¾‹

    Returns:
        OpenAIChatCompletionClient: é…ç½®å¥½çš„æ¨¡å‹å®¢æˆ·ç«¯
    """
    try:
        logger.info("ğŸ¤– [LLMå®¢æˆ·ç«¯] å¼€å§‹åˆ›å»ºOpenAIæ¨¡å‹å®¢æˆ·ç«¯")
        logger.info(f"   ğŸ“‹ æ¨¡å‹: {settings.aimodel.model}")
        logger.info(f"   ğŸŒ åŸºç¡€URL: {settings.aimodel.base_url}")
        logger.info(
            f"   ğŸ”‘ APIå¯†é’¥: {'*' * (len(settings.aimodel.api_key) - 8) + settings.aimodel.api_key[-8:] if settings.aimodel.api_key else 'None'}"
        )

        # åˆ›å»ºæ¨¡å‹å®¢æˆ·ç«¯
        client = OpenAIChatCompletionClient(
            model=settings.aimodel.model,
            base_url=settings.aimodel.base_url,
            api_key=settings.aimodel.api_key,
            model_info={
                "vision": False,
                "function_calling": True,
                "json_output": True,
                "family": ModelFamily.UNKNOWN,
                "structured_output": True,
                "multiple_system_messages": True,
            },
        )

        logger.success("âœ… [LLMå®¢æˆ·ç«¯] OpenAIæ¨¡å‹å®¢æˆ·ç«¯åˆ›å»ºæˆåŠŸ")
        return client

    except Exception as e:
        logger.error(f"âŒ [LLMå®¢æˆ·ç«¯] åˆ›å»ºOpenAIæ¨¡å‹å®¢æˆ·ç«¯å¤±è´¥: {e}")
        logger.error(f"   ğŸ› é”™è¯¯ç±»å‹: {type(e).__name__}")
        logger.error(f"   ğŸ“„ é”™è¯¯è¯¦æƒ…: {str(e)}")
        raise


# åˆ›å»ºå…¨å±€æ¨¡å‹å®¢æˆ·ç«¯å®ä¾‹
try:
    openai_model_client = create_openai_model_client()
    logger.info("ğŸŒŸ [LLMå®¢æˆ·ç«¯] å…¨å±€OpenAIæ¨¡å‹å®¢æˆ·ç«¯å®ä¾‹å·²åˆ›å»º")
except Exception as e:
    logger.error(f"âŒ [LLMå®¢æˆ·ç«¯] å…¨å±€æ¨¡å‹å®¢æˆ·ç«¯åˆ›å»ºå¤±è´¥: {e}")
    openai_model_client = None


def get_openai_model_client() -> OpenAIChatCompletionClient:
    """
    è·å–OpenAIæ¨¡å‹å®¢æˆ·ç«¯å®ä¾‹

    Returns:
        OpenAIChatCompletionClient: æ¨¡å‹å®¢æˆ·ç«¯å®ä¾‹

    Raises:
        RuntimeError: å¦‚æœæ¨¡å‹å®¢æˆ·ç«¯æœªåˆå§‹åŒ–
    """
    if openai_model_client is None:
        logger.error("âŒ [LLMå®¢æˆ·ç«¯] æ¨¡å‹å®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
        raise RuntimeError("OpenAIæ¨¡å‹å®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œè¯·æ£€æŸ¥é…ç½®")

    return openai_model_client


def validate_model_client() -> bool:
    """
    éªŒè¯æ¨¡å‹å®¢æˆ·ç«¯æ˜¯å¦å¯ç”¨

    Returns:
        bool: å®¢æˆ·ç«¯æ˜¯å¦å¯ç”¨
    """
    try:
        client = get_openai_model_client()
        if client is None:
            return False

        # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤šçš„éªŒè¯é€»è¾‘ï¼Œæ¯”å¦‚æµ‹è¯•è¿æ¥
        logger.debug("ğŸ” [LLMå®¢æˆ·ç«¯] æ¨¡å‹å®¢æˆ·ç«¯éªŒè¯é€šè¿‡")
        return True

    except Exception as e:
        logger.error(f"âŒ [LLMå®¢æˆ·ç«¯] æ¨¡å‹å®¢æˆ·ç«¯éªŒè¯å¤±è´¥: {e}")
        return False


# å¯¼å‡ºä¸»è¦æ¥å£
__all__ = [
    "openai_model_client",
    "get_openai_model_client",
    "create_openai_model_client",
    "validate_model_client",
]
