"""
AIæµ‹è¯•ç”¨ä¾‹ç”ŸæˆAPIè·¯ç”± - é‡æ–°è®¾è®¡ç‰ˆæœ¬
å®ç°ä¸¤ä¸ªæ ¸å¿ƒæ¥å£ï¼š
1. /generate/sse - å¯åŠ¨éœ€æ±‚åˆ†æå’Œåˆæ­¥ç”¨ä¾‹ç”Ÿæˆ
2. /feedback - å¤„ç†ç”¨æˆ·åé¦ˆï¼Œæ”¯æŒä¼˜åŒ–å’Œæœ€ç»ˆåŒ–
"""

import asyncio
import base64
import json
import uuid
from datetime import datetime
from pathlib import Path
from typing import List, Optional

import aiofiles
from fastapi import APIRouter, File, Form, HTTPException, Query, UploadFile
from loguru import logger
from pydantic import BaseModel
from sse_starlette.sse import EventSourceResponse

from backend.models.chat import FileUpload, TestCaseRequest
from backend.services.testcase_service import (
    FeedbackMessage,
    RequirementMessage,
    testcase_runtime,
    testcase_service,
)

router = APIRouter(prefix="/api/testcase", tags=["testcase"])


class FeedbackRequest(BaseModel):
    """ç”¨æˆ·åé¦ˆè¯·æ±‚æ¨¡å‹"""

    conversation_id: str
    feedback: str
    round_number: int
    previous_testcases: Optional[str] = ""


class GenerateRequest(BaseModel):
    """ç”Ÿæˆè¯·æ±‚æ¨¡å‹"""

    conversation_id: Optional[str] = None
    text_content: Optional[str] = None
    files: Optional[List[FileUpload]] = None
    round_number: int = 1


class StreamingGenerateRequest(BaseModel):
    """æµå¼ç”Ÿæˆè¯·æ±‚æ¨¡å‹"""

    conversation_id: Optional[str] = None
    text_content: Optional[str] = None
    files: Optional[List[FileUpload]] = None
    file_paths: Optional[List[str]] = None  # æ–°å¢ï¼šæ”¯æŒæ–‡ä»¶è·¯å¾„åˆ—è¡¨
    round_number: int = 1
    enable_streaming: bool = True


@router.post("/upload")
async def upload_files(
    user_id: int = Query(default=1, description="ç”¨æˆ·ID"),
    files: List[UploadFile] = File(...),
):
    """
    æ–‡ä»¶ä¸Šä¼ æ¥å£ - å‚è€ƒexampleså®ç°

    å¤„ç†æ–‡ä»¶ä¸Šä¼ å¹¶è¿”å›å­˜å‚¨è·¯å¾„ï¼Œä¾›åç»­æ–‡ä»¶è§£æä½¿ç”¨
    """
    logger.info(
        f"ğŸ“ [æ–‡ä»¶ä¸Šä¼ ] æ”¶åˆ°æ–‡ä»¶ä¸Šä¼ è¯·æ±‚ | ç”¨æˆ·ID: {user_id} | æ–‡ä»¶æ•°é‡: {len(files)}"
    )

    try:
        from pathlib import Path

        import aiofiles

        uploaded_files = []

        # åˆ›å»ºç”¨æˆ·ä¸“å±ä¸Šä¼ ç›®å½•
        upload_dir = Path("uploads") / str(user_id)
        upload_dir.mkdir(parents=True, exist_ok=True)
        logger.info(f"   ğŸ“‚ ä¸Šä¼ ç›®å½•: {upload_dir}")

        for i, file in enumerate(files):
            logger.info(f"   ğŸ“„ å¤„ç†æ–‡ä»¶ {i+1}: {file.filename}")

            # æ–‡ä»¶ç±»å‹éªŒè¯ï¼ˆå¯é€‰ï¼Œå½“å‰æ³¨é‡Šæ‰ä»¥æ”¯æŒæ›´å¤šæ ¼å¼ï¼‰
            # ALLOWED_TYPES = [
            #     "application/pdf",
            #     "application/msword",
            #     "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
            #     "text/plain"
            # ]
            # if file.content_type not in ALLOWED_TYPES:
            #     raise HTTPException(400, detail=f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file.content_type}")

            # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
            file_ext = Path(file.filename).suffix if file.filename else ""
            uuid_name = f"{uuid.uuid4().hex}{file_ext}"
            file_path = upload_dir / uuid_name
            logger.debug(f"   ğŸ’¾ æ–‡ä»¶ä¿å­˜è·¯å¾„: {file_path}")

            # æµå¼å†™å…¥æ–‡ä»¶å¹¶æ§åˆ¶å¤§å°
            max_size = 10 * 1024 * 1024  # 10MB
            total_size = 0

            async with aiofiles.open(file_path, "wb") as buffer:
                while chunk := await file.read(8192):
                    total_size += len(chunk)
                    if total_size > max_size:
                        await buffer.close()
                        file_path.unlink(missing_ok=True)
                        raise HTTPException(
                            413, detail=f"æ–‡ä»¶ {file.filename} å¤§å°è¶…è¿‡10MBé™åˆ¶"
                        )
                    await buffer.write(chunk)

            # æ„å»ºæ–‡ä»¶ä¿¡æ¯
            file_info = {
                "filePath": file_path.as_posix(),  # æ–‡ä»¶å®Œæ•´è·¯å¾„
                "fileId": uuid_name,  # å”¯ä¸€æ–‡ä»¶ID
                "fileName": file.filename,  # åŸå§‹æ–‡ä»¶å
                "contentType": file.content_type,  # æ–‡ä»¶ç±»å‹
                "size": total_size,  # æ–‡ä»¶å¤§å°
            }
            uploaded_files.append(file_info)

            logger.success(f"   âœ… æ–‡ä»¶ä¸Šä¼ æˆåŠŸ: {file.filename} -> {file_path}")

        logger.success(
            f"ğŸ‰ [æ–‡ä»¶ä¸Šä¼ ] æ‰€æœ‰æ–‡ä»¶ä¸Šä¼ å®Œæˆ | ç”¨æˆ·ID: {user_id} | æˆåŠŸ: {len(uploaded_files)} ä¸ª"
        )

        return {
            "success": True,
            "message": "æ–‡ä»¶ä¸Šä¼ æˆåŠŸ",
            "user_id": user_id,
            "files": uploaded_files,
            "total_files": len(uploaded_files),
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ [æ–‡ä»¶ä¸Šä¼ ] æ–‡ä»¶ä¸Šä¼ å¤±è´¥ | ç”¨æˆ·ID: {user_id} | é”™è¯¯: {e}")
        raise HTTPException(status_code=500, detail=f"æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {str(e)}")


@router.post("/generate/streaming")
async def generate_testcase_streaming(request: StreamingGenerateRequest):
    """
    æµå¼ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹æ¥å£ - POSTç‰ˆæœ¬

    åŠŸèƒ½ï¼šå¯åŠ¨éœ€æ±‚åˆ†æå’Œåˆæ­¥ç”¨ä¾‹ç”Ÿæˆï¼Œè¿”å›æµå¼è¾“å‡º
    æµç¨‹ï¼šç”¨æˆ·è¾“å…¥ â†’ éœ€æ±‚åˆ†ææ™ºèƒ½ä½“ â†’ æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆæ™ºèƒ½ä½“ â†’ æµå¼SSEè¿”å›

    æ”¯æŒçš„æµå¼è¾“å‡ºç±»å‹ï¼š
    1. streaming_chunk - æ™ºèƒ½ä½“çš„æµå¼è¾“å‡ºå— (ç±»ä¼¼ ModelClientStreamingChunkEvent)
    2. text_message - æ™ºèƒ½ä½“çš„å®Œæ•´è¾“å‡º (ç±»ä¼¼ TextMessage)
    3. task_result - åŒ…å«æ‰€æœ‰æ™ºèƒ½ä½“è¾“å‡ºçš„æœ€ç»ˆç»“æœ (ç±»ä¼¼ TaskResult)

    Args:
        request: æµå¼ç”Ÿæˆè¯·æ±‚å¯¹è±¡

    Returns:
        EventSourceResponse: SSEæµå¼å“åº”ï¼Œå®æ—¶è¿”å›æ™ºèƒ½ä½“å¤„ç†ç»“æœ
    """
    # ç”Ÿæˆæˆ–ä½¿ç”¨æä¾›çš„å¯¹è¯ID
    conversation_id = request.conversation_id or str(uuid.uuid4())

    logger.info(f"ğŸš€ [API-æµå¼ç”Ÿæˆ] æ”¶åˆ°æµå¼æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆè¯·æ±‚")
    logger.info(f"   ğŸ“‹ å¯¹è¯ID: {conversation_id}")
    logger.info(f"   ğŸ“ æ–‡æœ¬å†…å®¹é•¿åº¦: {len(request.text_content or '')}")
    logger.info(f"   ğŸ“ æ–‡ä»¶æ•°é‡: {len(request.files) if request.files else 0}")
    logger.info(f"   ğŸ”¢ è½®æ¬¡: {request.round_number}")
    logger.info(f"   ğŸŒŠ æµå¼æ¨¡å¼: {request.enable_streaming}")
    logger.info(f"   ğŸŒ è¯·æ±‚æ–¹æ³•: POST /api/testcase/generate/streaming")

    # åˆ›å»ºéœ€æ±‚æ¶ˆæ¯å¯¹è±¡
    logger.info(f"ğŸ“¦ [API-æµå¼ç”Ÿæˆ] åˆ›å»ºéœ€æ±‚æ¶ˆæ¯å¯¹è±¡ | å¯¹è¯ID: {conversation_id}")
    requirement = RequirementMessage(
        text_content=request.text_content or "",
        files=request.files or [],
        file_paths=request.file_paths or [],  # æ–°å¢ï¼šæ”¯æŒæ–‡ä»¶è·¯å¾„
        conversation_id=conversation_id,
        round_number=request.round_number,
    )
    logger.debug(f"   ğŸ“‹ éœ€æ±‚æ¶ˆæ¯: {requirement}")
    logger.success(
        f"âœ… [API-æµå¼ç”Ÿæˆ] éœ€æ±‚æ¶ˆæ¯å¯¹è±¡åˆ›å»ºå®Œæˆ | å¯¹è¯ID: {conversation_id}"
    )

    async def generate():
        """
        æµå¼SSEç”Ÿæˆå™¨å‡½æ•°

        æ”¯æŒAutoGené£æ ¼çš„æµå¼è¾“å‡ºï¼š
        1. streaming_chunk - æ¨¡æ‹Ÿ ModelClientStreamingChunkEvent
        2. text_message - æ¨¡æ‹Ÿ TextMessage
        3. task_result - æ¨¡æ‹Ÿ TaskResult

        Returns:
            AsyncGenerator: SSEæ ¼å¼çš„æ•°æ®æµ
        """
        try:
            logger.info(
                f"ğŸŒŠ [æµå¼SSEç”Ÿæˆå™¨] å¯åŠ¨æµå¼ç”Ÿæˆå™¨ | å¯¹è¯ID: {conversation_id}"
            )

            # å¯åŠ¨æµå¼ç”Ÿæˆ
            logger.info(
                f"ğŸš€ [æµå¼SSEç”Ÿæˆå™¨] å¯åŠ¨æµå¼æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆ | å¯¹è¯ID: {conversation_id}"
            )

            stream_count = 0
            async for stream_data in testcase_service.start_streaming_generation(
                requirement
            ):
                stream_count += 1
                stream_type = stream_data.get("type", "unknown")
                source = stream_data.get("source", "unknown")

                logger.info(f"ğŸ“¤ [æµå¼SSEç”Ÿæˆå™¨] å‘é€æµå¼æ•°æ® #{stream_count}")
                logger.info(f"   ğŸ·ï¸  ç±»å‹: {stream_type}")
                logger.info(f"   ğŸ¤– æ¥æº: {source}")
                logger.debug(
                    f"   ğŸ“„ å†…å®¹é•¿åº¦: {len(str(stream_data.get('content', '')))}"
                )

                # æ ¹æ®ç±»å‹æ·»åŠ ç‰¹æ®Šæ ‡è¯†
                if stream_type == "streaming_chunk":
                    # æµå¼è¾“å‡ºå—
                    content = stream_data.get("content", "")
                    logger.info(f"   ğŸ“¡ æµå¼å—: {source} | å†…å®¹: {content}")
                elif stream_type == "text_message":
                    # æ™ºèƒ½ä½“å®Œæ•´æ¶ˆæ¯
                    content = stream_data.get("content", "")
                    logger.info(
                        f"   ğŸ“ å®Œæ•´æ¶ˆæ¯: {source} | å†…å®¹é•¿åº¦: {len(content)} | å®Œæ•´å†…å®¹: {content}"
                    )
                elif stream_type == "task_result":
                    # ä»»åŠ¡ç»“æœ
                    logger.info(
                        f"   ğŸ ä»»åŠ¡ç»“æœ: {len(stream_data.get('messages', []))} æ¡æ¶ˆæ¯"
                    )

                # ç¡®ä¿æ¯ä¸ªæµå¼æ•°æ®éƒ½åŒ…å«conversation_id
                stream_data["conversation_id"] = conversation_id

                # å‘é€SSEæ•°æ® - EventSourceResponseä¼šè‡ªåŠ¨æ·»åŠ data:å‰ç¼€
                sse_data = json.dumps(stream_data, ensure_ascii=False)
                yield f"{sse_data}"
                logger.debug(f"   ğŸ“¡ SSEæ•°æ®å·²å‘é€: {len(sse_data)} å­—ç¬¦")

                # å¦‚æœæ˜¯ä»»åŠ¡ç»“æœï¼Œè¡¨ç¤ºå®Œæˆ
                if stream_type == "task_result":
                    logger.success(
                        f"ğŸ‰ [æµå¼SSEç”Ÿæˆå™¨] ä»»åŠ¡å®Œæˆ | å¯¹è¯ID: {conversation_id}"
                    )
                    break

            logger.success(
                f"ğŸ‰ [æµå¼SSEç”Ÿæˆå™¨] æµå¼ç”Ÿæˆå®Œæˆ | å¯¹è¯ID: {conversation_id}"
            )
            logger.info(f"   ğŸ“Š æ€»æµå¼æ•°æ®: {stream_count} æ¡")

        except Exception as e:
            logger.error(
                f"âŒ [æµå¼SSEç”Ÿæˆå™¨] ç”Ÿæˆè¿‡ç¨‹å‘ç”Ÿé”™è¯¯ | å¯¹è¯ID: {conversation_id}"
            )
            logger.error(f"   ğŸ› é”™è¯¯ç±»å‹: {type(e).__name__}")
            logger.error(f"   ğŸ“„ é”™è¯¯è¯¦æƒ…: {str(e)}")
            logger.error(f"   ğŸ“ é”™è¯¯ä½ç½®: æµå¼SSEç”Ÿæˆå™¨")

            # å‘é€é”™è¯¯æ¶ˆæ¯
            error_message = {
                "type": "error",
                "source": "system",
                "content": f"âŒ æµå¼ç”Ÿæˆå¤±è´¥: {str(e)}",
                "conversation_id": conversation_id,
                "timestamp": datetime.now().isoformat(),
            }
            error_data = json.dumps(error_message, ensure_ascii=False)
            yield f"{error_data}"
            logger.debug(f"   ğŸ“¡ é”™è¯¯æ¶ˆæ¯å·²å‘é€: {error_data}")

    return EventSourceResponse(
        generate(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Headers": "*",
        },
    )


# å·²åˆ é™¤ /generate/stream æ¥å£ - å·²è¢« /generate/sse æ¥å£æ›¿ä»£


# å·²åˆ é™¤ /generate æ¥å£ - å‰ç«¯æœªä½¿ç”¨ï¼Œå·²è¢« /generate/sse æ¥å£æ›¿ä»£


@router.post("/feedback/streaming")
async def submit_feedback_streaming(request: FeedbackRequest):
    """
    æµå¼å¤„ç†ç”¨æˆ·åé¦ˆæ¥å£ - POSTç‰ˆæœ¬

    åŠŸèƒ½ï¼šæ ¹æ®ç”¨æˆ·åé¦ˆå†³å®šåç»­æµç¨‹ï¼Œè¿”å›æµå¼è¾“å‡º
    - å½“è¾“å…¥æ„è§æ—¶ï¼šç”¨æˆ·åé¦ˆ + ç”¨ä¾‹è¯„å®¡ä¼˜åŒ–æ™ºèƒ½ä½“ï¼Œå‘å¸ƒæ¶ˆæ¯ï¼šç”¨ä¾‹ä¼˜åŒ–
    - å½“è¾“å…¥åŒæ„æ—¶ï¼šè¿”å›æœ€ç»ˆçš„ç»“æœï¼Œå®Œæˆæ•°æ®åº“è½åº“ï¼Œå‘å¸ƒæ¶ˆæ¯ï¼šç”¨ä¾‹ç»“æœ

    æ”¯æŒçš„æµå¼è¾“å‡ºç±»å‹ï¼š
    1. streaming_chunk - æ™ºèƒ½ä½“çš„æµå¼è¾“å‡ºå—
    2. text_message - æ™ºèƒ½ä½“çš„å®Œæ•´è¾“å‡º
    3. task_result - åŒ…å«æ‰€æœ‰æ™ºèƒ½ä½“è¾“å‡ºçš„æœ€ç»ˆç»“æœ

    Args:
        request: ç”¨æˆ·åé¦ˆè¯·æ±‚å¯¹è±¡ï¼ŒåŒ…å«åé¦ˆå†…å®¹å’Œç›¸å…³ä¿¡æ¯

    Returns:
        EventSourceResponse: SSEæµå¼å“åº”ï¼Œå®æ—¶è¿”å›æ™ºèƒ½ä½“å¤„ç†ç»“æœ
    """
    logger.info(f"ğŸ’¬ [API-æµå¼åé¦ˆ] æ”¶åˆ°æµå¼ç”¨æˆ·åé¦ˆè¯·æ±‚")
    logger.info(f"   ğŸ“‹ å¯¹è¯ID: {request.conversation_id}")
    logger.info(f"   ğŸ”¢ å½“å‰è½®æ¬¡: {request.round_number}")
    logger.info(f"   ğŸ’­ åé¦ˆå†…å®¹: {request.feedback}")
    logger.info(f"   ğŸ“„ ä¹‹å‰æµ‹è¯•ç”¨ä¾‹é•¿åº¦: {len(request.previous_testcases or '')}")
    logger.info(f"   ğŸŒ è¯·æ±‚æ–¹æ³•: POST /api/testcase/feedback/streaming")

    # æ£€æŸ¥è½®æ¬¡é™åˆ¶
    if request.round_number >= testcase_service.max_rounds:
        logger.warning(
            f"âš ï¸  [API-æµå¼åé¦ˆ] è¾¾åˆ°æœ€å¤§è½®æ¬¡é™åˆ¶ | å¯¹è¯ID: {request.conversation_id}"
        )

        async def error_generator():
            error_data = {
                "type": "error",
                "source": "system",
                "content": "å·²è¾¾åˆ°æœ€å¤§äº¤äº’è½®æ¬¡",
                "conversation_id": request.conversation_id,
                "max_rounds_reached": True,
                "timestamp": datetime.now().isoformat(),
            }
            yield f"{json.dumps(error_data, ensure_ascii=False)}"

        return EventSourceResponse(
            error_generator(),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "Access-Control-Allow-Origin": "*",
                "Access-Control-Allow-Headers": "*",
            },
        )

    # åˆ›å»ºåé¦ˆæ¶ˆæ¯å¯¹è±¡
    logger.info(
        f"ğŸ“¦ [API-æµå¼åé¦ˆ] åˆ›å»ºåé¦ˆæ¶ˆæ¯å¯¹è±¡ | å¯¹è¯ID: {request.conversation_id}"
    )
    next_round = request.round_number + 1
    feedback = FeedbackMessage(
        feedback=request.feedback,
        conversation_id=request.conversation_id,
        round_number=next_round,
        previous_testcases=request.previous_testcases,
    )
    logger.debug(f"   ğŸ“‹ åé¦ˆæ¶ˆæ¯: {feedback}")

    async def generate():
        """
        æµå¼åé¦ˆå¤„ç†ç”Ÿæˆå™¨å‡½æ•°

        Returns:
            AsyncGenerator: SSEæ ¼å¼çš„æ•°æ®æµ
        """
        try:
            logger.info(
                f"ğŸŒŠ [æµå¼åé¦ˆç”Ÿæˆå™¨] å¯åŠ¨æµå¼åé¦ˆå¤„ç† | å¯¹è¯ID: {request.conversation_id}"
            )

            # åˆ†æåé¦ˆç±»å‹
            is_approval = (
                "åŒæ„" in request.feedback or "APPROVE" in request.feedback.upper()
            )
            logger.info(f"ğŸ” [æµå¼åé¦ˆç”Ÿæˆå™¨] åé¦ˆç±»å‹åˆ†æ")
            logger.info(f"   ğŸ“ åŸå§‹åé¦ˆ: '{request.feedback}'")
            logger.info(f"   âœ… æ˜¯å¦åŒæ„: {is_approval}")

            # å¯åŠ¨æµå¼åé¦ˆå¤„ç†
            stream_count = 0
            async for stream_data in testcase_service.process_streaming_feedback(
                feedback
            ):
                stream_count += 1
                stream_type = stream_data.get("type", "unknown")
                source = stream_data.get("source", "unknown")

                logger.info(f"ğŸ“¤ [æµå¼åé¦ˆç”Ÿæˆå™¨] å‘é€æµå¼æ•°æ® #{stream_count}")
                logger.info(f"   ğŸ·ï¸  ç±»å‹: {stream_type}")
                logger.info(f"   ğŸ¤– æ¥æº: {source}")
                logger.debug(
                    f"   ğŸ“„ å†…å®¹é•¿åº¦: {len(str(stream_data.get('content', '')))}"
                )

                # æ ¹æ®ç±»å‹æ·»åŠ ç‰¹æ®Šæ ‡è¯†
                if stream_type == "streaming_chunk":
                    # æµå¼è¾“å‡ºå—
                    content = stream_data.get("content", "")
                    logger.info(f"   ğŸ“¡ æµå¼å—: {source} | å†…å®¹: {content}")
                elif stream_type == "text_message":
                    # æ™ºèƒ½ä½“å®Œæ•´æ¶ˆæ¯
                    content = stream_data.get("content", "")
                    logger.info(
                        f"   ğŸ“ å®Œæ•´æ¶ˆæ¯: {source} | å†…å®¹é•¿åº¦: {len(content)} | å®Œæ•´å†…å®¹: {content}"
                    )
                elif stream_type == "task_result":
                    # ä»»åŠ¡ç»“æœ
                    logger.info(
                        f"   ğŸ ä»»åŠ¡ç»“æœ: {len(stream_data.get('messages', []))} æ¡æ¶ˆæ¯"
                    )

                # ç¡®ä¿æ¯ä¸ªæµå¼æ•°æ®éƒ½åŒ…å«conversation_id
                stream_data["conversation_id"] = request.conversation_id

                # å‘é€SSEæ•°æ® - EventSourceResponseä¼šè‡ªåŠ¨æ·»åŠ data:å‰ç¼€
                sse_data = json.dumps(stream_data, ensure_ascii=False)
                yield f"{sse_data}"
                logger.debug(f"   ğŸ“¡ SSEæ•°æ®å·²å‘é€: {len(sse_data)} å­—ç¬¦")

                # å¦‚æœæ˜¯ä»»åŠ¡ç»“æœï¼Œè¡¨ç¤ºå®Œæˆ
                if stream_type == "task_result":
                    logger.success(
                        f"ğŸ‰ [æµå¼åé¦ˆç”Ÿæˆå™¨] åé¦ˆå¤„ç†å®Œæˆ | å¯¹è¯ID: {request.conversation_id}"
                    )
                    break

            logger.success(
                f"ğŸ‰ [æµå¼åé¦ˆç”Ÿæˆå™¨] æµå¼åé¦ˆå¤„ç†å®Œæˆ | å¯¹è¯ID: {request.conversation_id}"
            )
            logger.info(f"   ğŸ“Š æ€»æµå¼æ•°æ®: {stream_count} æ¡")

        except Exception as e:
            logger.error(
                f"âŒ [æµå¼åé¦ˆç”Ÿæˆå™¨] å¤„ç†è¿‡ç¨‹å‘ç”Ÿé”™è¯¯ | å¯¹è¯ID: {request.conversation_id}"
            )
            logger.error(f"   ğŸ› é”™è¯¯ç±»å‹: {type(e).__name__}")
            logger.error(f"   ğŸ“„ é”™è¯¯è¯¦æƒ…: {str(e)}")
            logger.error(f"   ğŸ“ é”™è¯¯ä½ç½®: æµå¼åé¦ˆç”Ÿæˆå™¨")

            # å‘é€é”™è¯¯æ¶ˆæ¯
            error_message = {
                "type": "error",
                "source": "system",
                "content": f"âŒ åé¦ˆå¤„ç†å¤±è´¥: {str(e)}",
                "conversation_id": request.conversation_id,
                "timestamp": datetime.now().isoformat(),
            }
            error_data = json.dumps(error_message, ensure_ascii=False)
            yield f"{error_data}"
            logger.debug(f"   ğŸ“¡ é”™è¯¯æ¶ˆæ¯å·²å‘é€: {error_data}")

    return EventSourceResponse(
        generate(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Headers": "*",
        },
    )


# å·²åˆ é™¤ /conversation/{id} GET æ¥å£ - å‰ç«¯æœªä½¿ç”¨


# å·²åˆ é™¤ /conversation/{id} DELETE æ¥å£ - å‰ç«¯æœªä½¿ç”¨


# å·²åˆ é™¤ /stats æ¥å£ - å‰ç«¯æœªä½¿ç”¨


# æ—§çš„GETæ¥å£å·²ç§»é™¤ï¼Œç°åœ¨ä½¿ç”¨POSTæµå¼æ¥å£


@router.get("/history/{conversation_id}")
async def get_conversation_history(conversation_id: str):
    """
    è·å–å¯¹è¯å†å²æ¥å£

    åŠŸèƒ½ï¼šè·å–æŒ‡å®šå¯¹è¯çš„å®Œæ•´å†å²è®°å½•å’Œæ¶ˆæ¯åˆ—è¡¨

    Args:
        conversation_id: å¯¹è¯å”¯ä¸€æ ‡è¯†ç¬¦

    Returns:
        dict: åŒ…å«å†å²è®°å½•å’Œæ¶ˆæ¯åˆ—è¡¨çš„å“åº”æ•°æ®
    """
    logger.info(f"ğŸ“š [API-å†å²æ¥å£] æ”¶åˆ°è·å–å¯¹è¯å†å²è¯·æ±‚")
    logger.info(f"   ğŸ“‹ å¯¹è¯ID: {conversation_id}")
    logger.info(f"   ğŸŒ è¯·æ±‚æ–¹æ³•: GET /api/testcase/history/{conversation_id}")

    try:
        # æ­¥éª¤1: è·å–å†å²è®°å½•
        logger.info(
            f"ğŸ“– [API-å†å²æ¥å£] æ­¥éª¤1: è·å–å†å²è®°å½• | å¯¹è¯ID: {conversation_id}"
        )
        history = await testcase_service.get_history(conversation_id)
        logger.info(f"   ğŸ“Š å†å²è®°å½•æ•°é‡: {len(history)}")
        logger.debug(f"   ğŸ“‹ å†å²è®°å½•: {history}")

        # æ­¥éª¤2: è·å–æ¶ˆæ¯åˆ—è¡¨
        logger.info(
            f"ğŸ“¨ [API-å†å²æ¥å£] æ­¥éª¤2: è·å–æ¶ˆæ¯åˆ—è¡¨ | å¯¹è¯ID: {conversation_id}"
        )
        messages = testcase_service.get_messages(conversation_id)
        logger.info(f"   ğŸ“Š æ¶ˆæ¯æ•°é‡: {len(messages)}")

        # ç»Ÿè®¡æ¶ˆæ¯ç±»å‹
        message_types = {}
        for msg in messages:
            msg_type = msg.get("message_type", "unknown")
            message_types[msg_type] = message_types.get(msg_type, 0) + 1
        logger.info(f"   ğŸ“Š æ¶ˆæ¯ç±»å‹ç»Ÿè®¡: {message_types}")

        # æ­¥éª¤3: æ„é€ å“åº”æ•°æ®
        logger.info(
            f"ğŸ“‹ [API-å†å²æ¥å£] æ­¥éª¤3: æ„é€ å“åº”æ•°æ® | å¯¹è¯ID: {conversation_id}"
        )
        response_data = {
            "conversation_id": conversation_id,
            "history": history,
            "messages": messages,
            "total_messages": len(messages),
            "total_history": len(history),
            "message_types": message_types,
        }
        logger.debug(f"   ğŸ“¦ å“åº”æ•°æ®: {response_data}")

        logger.success(
            f"âœ… [API-å†å²æ¥å£] å¯¹è¯å†å²è·å–æˆåŠŸ | å¯¹è¯ID: {conversation_id}"
        )
        logger.info(f"   ğŸ“Š å†å²è®°å½•: {len(history)} æ¡")
        logger.info(f"   ğŸ“Š æ¶ˆæ¯è®°å½•: {len(messages)} æ¡")

        return response_data

    except Exception as e:
        logger.error(f"âŒ [API-å†å²æ¥å£] è·å–å¯¹è¯å†å²å¤±è´¥ | å¯¹è¯ID: {conversation_id}")
        logger.error(f"   ğŸ› é”™è¯¯ç±»å‹: {type(e).__name__}")
        logger.error(f"   ğŸ“„ é”™è¯¯è¯¦æƒ…: {str(e)}")
        logger.error(f"   ğŸ“ é”™è¯¯ä½ç½®: å†å²æ¥å£å¤„ç†è¿‡ç¨‹")

        raise HTTPException(status_code=500, detail=str(e))


@router.delete("/conversation/{conversation_id}")
async def clear_conversation_history(conversation_id: str):
    """
    æ¸…é™¤å¯¹è¯å†å²æ¥å£

    åŠŸèƒ½ï¼šæ¸…é™¤æŒ‡å®šå¯¹è¯çš„æ‰€æœ‰å†å²è®°å½•å’Œæ¶ˆæ¯

    Args:
        conversation_id: å¯¹è¯å”¯ä¸€æ ‡è¯†ç¬¦

    Returns:
        dict: æ¸…é™¤ç»“æœ
    """
    logger.info(f"ğŸ—‘ï¸ [API-æ¸…é™¤å†å²] æ”¶åˆ°æ¸…é™¤å¯¹è¯å†å²è¯·æ±‚")
    logger.info(f"   ğŸ“‹ å¯¹è¯ID: {conversation_id}")
    logger.info(f"   ğŸŒ è¯·æ±‚æ–¹æ³•: DELETE /api/testcase/conversation/{conversation_id}")

    try:
        # æ¸…é™¤å†å²è®°å½•å’Œæ¶ˆæ¯
        await testcase_service.clear_conversation(conversation_id)

        logger.success(
            f"âœ… [API-æ¸…é™¤å†å²] å¯¹è¯å†å²æ¸…é™¤æˆåŠŸ | å¯¹è¯ID: {conversation_id}"
        )

        return {
            "success": True,
            "message": "å¯¹è¯å†å²å·²æ¸…é™¤",
            "conversation_id": conversation_id,
            "timestamp": datetime.now().isoformat(),
        }

    except Exception as e:
        logger.error(f"âŒ [API-æ¸…é™¤å†å²] æ¸…é™¤å¯¹è¯å†å²å¤±è´¥ | å¯¹è¯ID: {conversation_id}")
        logger.error(f"   ğŸ› é”™è¯¯ç±»å‹: {type(e).__name__}")
        logger.error(f"   ğŸ“„ é”™è¯¯è¯¦æƒ…: {str(e)}")
        logger.error(f"   ğŸ“ é”™è¯¯ä½ç½®: æ¸…é™¤å†å²æ¥å£å¤„ç†è¿‡ç¨‹")

        raise HTTPException(status_code=500, detail=str(e))
